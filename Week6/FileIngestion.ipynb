{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f74b2145",
   "metadata": {},
   "source": [
    "# Data Glacier - Nahari Terena - Week6\n",
    "## Week 6: File ingestion and schema validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5447bcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2059346639"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "os.path.getsize('C:/Users/Olnalu/Desktop/Nahari/DataGlacier/Week6/dataset_CNPJ.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ac2ee",
   "metadata": {},
   "source": [
    "### Reading data with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9635b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with dask:  0.03351473808288574 sec\n"
     ]
    }
   ],
   "source": [
    "from dask import dataframe as dd\n",
    "start = time.time()\n",
    "dask_df = dd.read_csv('C:/Users/Olnalu/Desktop/Nahari/DataGlacier/dataset_CNPJ.csv', sep = \";\")\n",
    "end = time.time()\n",
    "print(\"Read csv with dask: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c7822",
   "metadata": {},
   "source": [
    "### Read with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5261b8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with pandas:  292.1952292919159 sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "start = time.time()\n",
    "df = pd.read_csv('C:/Users/Olnalu/Desktop/Nahari/DataGlacier/Week6/dataset_CNPJ.csv', sep = \";\", encoding = 'latin-1')\n",
    "end = time.time()\n",
    "print(\"Read csv with pandas: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa77c83",
   "metadata": {},
   "source": [
    "### Reading data with DictReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624226fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with DictReader:  0.0019922256469726562 sec\n"
     ]
    }
   ],
   "source": [
    "import csv  \n",
    "\n",
    "start = time.time()\n",
    "with open('C:/Users/Olnalu/Desktop/Nahari/DataGlacier/Week6/dataset_CNPJ.csv') as csvfile:  \n",
    "    data = csv.DictReader(csvfile)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Read csv with DictReader: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92f0969",
   "metadata": {},
   "source": [
    "Although, DictReader is faster than Dask, it imports everything as strings, while the other methods try to guess the data types of each column separately and possibly do multiple other validations upon import.\n",
    "Therefore, in cases when you know that the columns present in the data are all in string format already, csv.DictReader is the method to go for.\n",
    "In this specific case, we will use Dask instead of DictReader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e422393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe as dd\n",
    "df = dd.read_csv('C:/Users/Olnalu/Desktop/Nahari/DataGlacier/Week6/dataset_CNPJ.csv', sep = \";\", dtype={'CODE_SIZE': 'object',\n",
    "       'INCOME': 'object',\n",
    "       'STATE': 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64b75ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 7 entries, CNPJ to STATE\n",
      "dtypes: object(4), int64(3)"
     ]
    }
   ],
   "source": [
    "#No. of Rows\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8064e8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32297432"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc281879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CNPJ', 'NAME', 'CODE', 'QUALIFICATION', 'INCOME', 'CODE_SIZE',\n",
       "       'STATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e23e64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No, of Columns\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a3715e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olnalu\\AppData\\Local\\Temp\\ipykernel_7412\\418848558.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns=df.columns.str.replace('[#,@,&]','')\n"
     ]
    }
   ],
   "source": [
    "# remove special character\n",
    "df.columns=df.columns.str.replace('[#,@,&]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7555ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove white space from columns\n",
    "df.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1342105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "798098ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing utility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utility.py\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.load(stream, Loader=yaml.Loader)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "def col_header_val(df,table_config):\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]','_',regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns = list(map(lambda x: replacer(x,'_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns =list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce7e7a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing store.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile store.yaml\n",
    "file_type: csv\n",
    "dataset_name: file\n",
    "file_name: Rate\n",
    "table_name: cnpj\n",
    "inbound_delimiter: \";\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - CNPJ\n",
    "    - NAME \n",
    "    - CODE \n",
    "    - QUALIFICATION\n",
    "    - INCOME\n",
    "    - CODE_SIZE\n",
    "    - STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e3de7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n",
      "C:\\Users\\Olnalu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:788: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv(f, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\00.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\01.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\02.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\03.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\04.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\05.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\06.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\07.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\08.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\09.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\10.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\11.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\12.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\13.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\14.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\15.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\16.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\17.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\18.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\19.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\20.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\21.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\22.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\23.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\24.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\25.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\26.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\27.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\28.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\29.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\30.part',\n",
       " 'C:\\\\Users\\\\Olnalu\\\\Desktop\\\\Nahari\\\\DataGlacier\\\\Week6\\\\Rate.csv.gz\\\\31.part']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import csv\n",
    "import gzip\n",
    "\n",
    "from dask import dataframe as dd\n",
    "df = dd.read_csv('C:/Users/Olnalu/Desktop/Nahari/DataGlacier/Week6/dataset_CNPJ.csv', sep = \";\", dtype={'CODE_SIZE': 'object',\n",
    "       'INCOME': 'object',\n",
    "       'STATE': 'object'})\n",
    "\n",
    "# Write csv in gz format in pipe separated text file (|)\n",
    "df.to_csv('Rate.csv.gz',\n",
    "          sep=';',\n",
    "          header=True,\n",
    "          index=False,\n",
    "          quoting=csv.QUOTE_ALL,\n",
    "          compression='gzip',\n",
    "          quotechar='\"',\n",
    "          doublequote=True,\n",
    "          line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c8c5bb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00.part\n",
      "01.part\n",
      "02.part\n",
      "03.part\n",
      "04.part\n",
      "05.part\n",
      "06.part\n",
      "07.part\n",
      "08.part\n",
      "09.part\n",
      "10.part\n",
      "11.part\n",
      "12.part\n",
      "13.part\n",
      "14.part\n",
      "15.part\n",
      "16.part\n",
      "17.part\n",
      "18.part\n",
      "19.part\n",
      "20.part\n",
      "21.part\n",
      "22.part\n",
      "23.part\n",
      "24.part\n",
      "25.part\n",
      "26.part\n",
      "27.part\n",
      "28.part\n",
      "29.part\n",
      "30.part\n",
      "31.part\n"
     ]
    }
   ],
   "source": [
    "#number of files in gz format folder\n",
    "import os\n",
    "entries = os.listdir('C:/Users/Olnalu/Desktop/Nahari/DataGlacier/Week6/Rate.csv.gz/')\n",
    "for entry in entries:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "beda9ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12288"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size of the gz format folder\n",
    "os.path.getsize('C:/Users/Olnalu/Desktop/Nahari/DataGlacier/Week6/Rate.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687efe9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
